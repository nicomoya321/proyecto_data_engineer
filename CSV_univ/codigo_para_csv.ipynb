{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "vMFcRKrvvPJe",
        "outputId": "9de17f32-8a74-4a51-bc53-a2cde9e9e41e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-fc607a9be530>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLOG_ETL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mROOT_CSV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mROOT_SQL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mROOT_TXT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdb_connection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_engine_connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_txt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_filename_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'config'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import logging\n",
        "import os\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "from config1.cfg import LOG_ETL, ROOT_CSV, ROOT_SQL, ROOT_TXT\n",
        "from db.db_connection import create_engine_connection\n",
        "from utils.utils import create_folder, create_txt, get_filename_path\n",
        "from utils.transform import normalize_data\n",
        "\n",
        "# Use el log que cree en la etl\n",
        "log_name = LOG_ETL + datetime.today().strftime('%Y-%m-%d')\n",
        "logger = logging.getLogger(log_name)\n",
        "\n",
        "\n",
        "def extract_data():\n",
        "   \n",
        "    logger.info('*task_exctract')\n",
        "   \n",
        "    create_folder(ROOT_CSV)\n",
        "   \n",
        "    engine = create_engine_connection()\n",
        "  \n",
        "    sql_files = get_filename_path(ROOT_SQL)\n",
        "\n",
        "    with engine.connect() as connection:\n",
        "        \n",
        "        for sql_file_name, sql_full_path in sql_files.items():\n",
        "            with open(sql_full_path) as f:\n",
        "               \n",
        "                query = f.read()\n",
        "                logger.info('Extracting data from {}'.format(sql_file_name))\n",
        "               #extrayendo y convirtiendo a fichero sql\n",
        "                result = connection.execute(query)\n",
        "                \n",
        "                df = pd.DataFrame(result)\n",
        "                logger.info('Writing information to csv.')\n",
        "                \n",
        "                df.to_csv(os.path.join(\n",
        "                    ROOT_CSV, f'{sql_file_name[:-4]}.csv'), index=False)\n",
        "    logger.info('Extracting data from database.')\n",
        "    #csv obtenidos\n",
        "\n",
        "def transform_data():\n",
        "  \n",
        "    logger.info('transform_task')\n",
        "    \n",
        "    create_folder(ROOT_TXT)\n",
        "\n",
        "    csv_files = get_filename_path(ROOT_CSV)\n",
        "    for csv_name, csv_path in csv_files.items():\n",
        "        logger.info('Working on {} file.'.format(csv_name))\n",
        "       \n",
        "        dataframe = pd.read_csv(csv_path)\n",
        "        \n",
        "        logger.info('Clearing data on {} file.'.format(csv_name))\n",
        "        dataframe = normalize_data(dataframe)\n",
        "       \n",
        "        logger.info('Creating txt for {} file.'.format(csv_name))\n",
        "        create_txt(dataframe, csv_name[:-4])\n",
        "    logger.info('Transform data from dataframe/csv.')\n",
        "\n",
        "\n",
        "def load_data():\n",
        "   \n",
        "    logger.info('data_load')\n",
        "    logger.info('Loading data to S3.')\n",
        "\n"
      ]
    }
  ]
}